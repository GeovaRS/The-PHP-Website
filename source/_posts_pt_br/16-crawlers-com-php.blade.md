---
lang: pt-br
slug: como-escrever-crawlers-em-php
title: Como escrever crawlers decentes com PHP
category: guides
createdAt: 2020-07-20
sitemap:
  lastModified: 2020-07-20
image:
  url: /assets/images/posts/16-many-books-and-magazines-640.webp
  alt: 'Muitos livros e revistas.'
tags:
  - crawlers
  - guia
meta:
  description:
    Depois deste artigo vocÃª vai perceber o quanto vocÃª sofreu com
    seus crawlers em PHP. EXISTE uma forma melhor. Deixa eu lhe
    mostrar ğŸ˜‰
  twitter:
    card: summary
    site: '@nawarian'
---

[Read in English](/en/issue/how-to-write-crawlers-with-php)

VocÃª provavelmente jÃ¡ viu vÃ¡rios posts sobre como escrever crawlers com php.
O que difere este post dos outros? Eu garanto que vocÃª nÃ£o precisa se malucar
com expressÃµes regulares, variÃ¡veis globais e todo esse tipo de coisa irritante.

NÃ³s vamos usar uma ferramenta maravilhosa chamada `spatie/crawler` que vai nos
forcnecer uma Ã³tima interface para escrever crawlers sem ir Ã  loucura!

**Abaixo tem um vÃ­deo meu codificando este crawler. Ã‰ sÃ³ rolar a pÃ¡gina atÃ© o
vÃ­deo se tu quiser pular direto pra aÃ§Ã£o. ğŸ˜‰**

## Nosso caso de uso

Este crawler vai ser bem simplÃ£o e pretende buscar nomes, apelidos e e-mails
do diretÃ³rio oficial do PHP sobre pessoas que contribuÃ­ram com a linguagem de
alguma forma.

VocÃª pode olhar o repositÃ³rio nesta url aqui: [https://people.php.net](https://people.php.net).

## Configurando o ambiente

Montar o ambiente vai ser bem rÃ¡pido, eu vou sÃ³ copiar as sessÃµes _composer_
e _php_ desse outro post que eu escrevi sobre [como montar um ambiente com docker rapidex](/br/edicao/php-docker-setup-rapido).

Meu arquivo _docker-compose.yml_ ficou assim:

```yaml
version: '3'
services:
  composer:
    image: composer:1.9.3
    environment:
      - COMPOSER_CACHE_DIR=/app/.cache/composer
    volumes:
      - .:/app
    restart: never

  php:
    image: php:7.4-cli
    restart: never
    volumes:
      - .:/app
    working_dir: /app
```

Agora vamos instalar os pacotes:

```bash
$ docker-compose run \
  composer require \
    spatie/crawler \
    symfony/css-selector
```

Tudo o que a gente precisa agora Ã© um arquivo pra executar, vamos criar
um arquivo bin/crawler.php:

```bash
$ mkdir bin
$ touch bin/crawler.php
```

Massa! Agora vamos adicionar o autoload nesse arquivo e estamos prontos pra comeÃ§ar:

```php
// bin/crawler.php
<?php

require_once __DIR__ . 
  '/../vendor/autoload.php';
```

De agora em diante a gente pode rodar nosso crawler com o seguinte comando:

```bash
$ docker-compose run php \
  php bin/crawler.php
```

## Vamos analizar o site alvo

Normalmente a gente deveria navegar pelo website e entender como ele funciona:
padrÃµes de url, chamadas ajax, tokens csrf, se feeds ou APIs estÃ£o disponÃ­veis.

Neste caso nenhuma das opÃ§Ãµes estÃ¡ disponÃ­vel. A gente precisa criar um crawler
cruzÃ£o mesmo que vai buscar pÃ¡ginas em HTML e interpretÃ¡-las.

Eu vejo alguns padrÃµes de URL:
- PÃ¡gina de perfil: people.php.net/{nickname}
- PÃ¡gina de diretÃ³rio: people.php.net/?page={number}
- Links externos

Parece simples! A gente sÃ³ precisa se preocupar em interpretar o HTML dentro
de pÃ¡ginas de perfil e ignorar o restante.

Ao verificar a pÃ¡gina de perfil podemos perceber rapidamente que os seletores
importantes pra gente sÃ£o:
- Nome: `h1[property=foaf:name]`
- Apelido: `h1[property=foaf:nick]`

A gente tambÃ©m pode confiar que o e-mail das pessoas segue o padrÃ£o "{apelido}@php.net".

Com essa informaÃ§Ã£o, bora codar!

## Obtendo dados pÃºblicos de todas as pessoas que contribuÃ­ram com o PHP 

Abaixo vocÃª encontra o cÃ³digo, mas se vocÃª prefere mais vÃ­deos, dÃ¡ uma ligadinha
nesse aqui que eu fiz pra ti:

<iframe style="margin: auto;" width="560" height="315" src="https://www.youtube.com/embed/HaMoYhTV1hI?start=21" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## MÃ£o na massa!

O pacote `spatie/crawler` traz duas classes abstratas muito importantes - que
eu adoraria que fossem interfaces.

Uma delas Ã© a classe `CrawlObserver`, onde a gente pode se conectar aos passos
de obter uma pÃ¡gina e manipular respostas http. A nossa lÃ³gica entra aqui.

Eu vou escrever um observer rapidinho com uma classe anÃ´nima abaixo:

```php
$observer = new class
  extends CrawlObserver
{
  public function crawled(
    $url,
    $response,
    $foundOnurl
  ) {
    $domCrawler = new DomCrawler(
      (string) $response->getBody()
    );
    
    $name = $domCrawler
      ->filter('h1[property="foaf:name"]')
      ->first()
      ->text();
    $nick = $domCrawler
      ->filter('h2[property="foaf:nick"]')
      ->first()
      ->text();
    $email = "{$nick}@php.net";
    
    echo "[{$email}] {$name} - {$nick}" . PHP_EOL;
  }
};
```

A lÃ³gica acima vai buscar as propriedades que esperamos das pÃ¡ginas de
perfil. Ã‰ claro que a gente deveria tambÃ©m verificar se estamos na pÃ¡gina
correta ou nÃ£o.

Agora, o prÃ³ximo passo importante Ã© a classe abstrata `CrawlProfile`. Com
esta classe a gente consegue decidir se uma URL deveria ou nÃ£o ser acessada
por um observer. Vamos criar tambÃ©m como classe anÃ´nima:

```php
$profile = new class
  extends CrawlProfile
{
  public function shouldCrawl(
    $url
  ): bool {
    return $url->getHost() ===
      'people.php.net';
  }
};
```

Acima a gente definiu que queremos seguir apenas links internos. Isso porque
esse website cria links pra vÃ¡rios outros repositÃ³rios. E a gente nÃ£o quer
crawlear todo o universo php, certo?

Com essas duas instÃ¢ncias em mÃ£os, podemos jÃ¡ preparar o crawler e iniciar
a busca:

```php
Crawler::create()
  ->setCrawlObserver($observer)
  ->setCrawlProfile($profile)
  ->setDelayBetweenRequests(500)
  ->startCrawling(
    'https://people.php.net/'
  );
```

**Importante!** Reparou naquele `setDelayBetweenRequests(500)`? Ele faz com que
o crawler vÃ¡ buscar apenas uma URL a cada 500 milisegundos. Isso Ã© porque a gente
nÃ£o quer derrubar esse site, certo? (SÃ©riÃ£o, nÃ£o derruba esse site. Se tu quer fazer
maldade, busca um site do governo ou coisa do gÃªnero ğŸ‘€)

## E Ã© isso!

RÃ¡pido e prÃ¡tico, e mais importante de tudo: sem loucuras! O `spatie/crawler` tem uma
interface muito massa que simplifica demais o processo.

Se vocÃª juntar essa ferramenta com uma injeÃ§Ã£o de dependÃªncias e enfileiramento vocÃª
terÃ¡ resultados profissionais.

Me dÃ¡ um toque no twitter se vocÃª tiver dÃºvidas!
Uma abraÃ§o! ğŸ‘‹

<div class="align-right">
  --
  <a href="https://twitter.com/nawarian" rel="nofollow">
    @nawarian
  </a>
</div>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "TechArticle",
  "headline": "Como escrever crawlers decentes com PHP",
  "description": "Depois deste artigo vocÃª vai perceber o quanto vocÃª sofreu com seus crawlers em PHP. EXISTE uma forma melhor.",
  "image": [
    "{{ $page->getBaseUrl() }}/assets/images/posts/16-many-books-and-magazines-640.webp"
   ],
  "datePublished": "2020-07-20T00:00:00+08:00",
  "dateModified": "2020-07-20T00:00:00+08:00",
  "author": {
    "@type": "Person",
    "name": "Nawarian NÃ­ckolas Da Silva"
  },
   "publisher": {
    "@type": "Organization",
    "name": "ThePHP Website",
    "logo": {
      "@type": "ImageObject",
      "url": "https://thephp.website/favicon.ico"
    }
  }
}
</script>
